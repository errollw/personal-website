<!doctype html>
<html>

<head>
    <meta charset="utf-8">
    <title>Erroll Wood &ndash; Publications</title>
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <!-- stylesheets -->
    <link rel="stylesheet" href="/css/normalize.css">
    <link rel="stylesheet" href="/css/styles2.css">
    <!-- javascript -->
    <script type='text/javascript' src='/js/lodash.js'></script>
    <script type='text/javascript' src='/js/jquery-2.0.3.js'></script>
    <script type='text/javascript' src='/js/jquery.scrollTo-1.4.3.1-min.js'></script>
    <script type='text/javascript' src='/js/init_site.js'></script>
</head>

<body>

    <section>
        <h1>Publications</h1>
        <article>
            <p>Here you can find my research publications, presentations and other writings completed during the course of my degrees &ndash; <a href="http://www.cl.cam.ac.uk/teaching/" class='p-out'>Computer Science Tripos</a> Part II and Part III.</p>
        </article>
    </section>

    <section>
        <h2>2015</h2>
        <img class='sixth' src="iccv2015.jpg" style="margin-bottom:1rem;">
        <aside class='five-sixths omega'>
            <p>
                <a href="http://arxiv.org/abs/1505.05916">Rendering of Eyes for Eye-Shape Registration and Gaze Estimation</a> <br/>
                <b>E. Wood</b>, T. Baltrusaitis, X. Zhang, Y. Sugano, P. Robinson, and A. Bulling<br/>
                <i>International Conference for Computer Vision 2015 (to appear)</i> <br/>
                <a href="iccv2015.pdf">paper</a>
                <a href="https://www.youtube.com/watch?v=q1Jmo5z0K08">video</a>
                <a href="http://arxiv.org/abs/1505.05916">arXiv</a>
                <a href="http://www.technologyreview.com/view/537891/virtual-eyes-train-deep-learning-algorithm-to-recognize-gaze-direction/">press (MIT)</a>
            </p>
        </aside>
    </section>

    <section>
        <h2>2014</h2>
        <img class='sixth' src="its2014.jpg" style="margin-bottom:1rem;">
        <aside class='five-sixths omega' style="margin-bottom:1rem;">
            <p>
                <a href="https://netboards.cl.cam.ac.uk/secure/">NetBoards: Investigating a Collection of Personal Noticeboard Displays in the Workplace</a> <br/>
				<b>Erroll Wood</b> and Peter Robinson <br/>
                <i>Interactive Tabletops &amp; Surfaces 2014 (full paper, invited demo)</i> <br/>
                <a href="https://netboards.cl.cam.ac.uk/secure/">project page</a>
                <a href="its2014.pdf">paper</a>
                <a href="its2014.pptx">presentation</a>
                <a href="https://github.com/errollw/smartboards2">code</a>
            </p>
        </aside>
    </section>

    <section>
        <img class='sixth' src="etra2014.jpg">
        <aside class='five-sixths omega'>
            <p>
                <a href="http://www.cl.cam.ac.uk/research/rainbow/projects/eyetab/">EyeTab: Model-based gaze estimation on unmodified tablet computers</a> <br/>
				<b>Erroll Wood</b> and Andreas Bulling <br/>
                <i>Eye-Tracking Research &amp; Applications 2014 (short paper, oral)</i> <br/>
                <a href="http://www.cl.cam.ac.uk/research/rainbow/projects/eyetab/">project page</a>
                <a href="http://www.cl.cam.ac.uk/research/rainbow/projects/eyetab/files/eww23_etra2014.pdf">paper</a>
                <a href="https://github.com/errollw/EyeTab/">code</a>
            </p>
        </aside>
    </section>

    <section>
        <h2>2013</h2>
        <img class='sixth' src="part_3_diss.jpg">
        <aside class='five-sixths'>
            <p>
                <a href="/assets/eww23_part3_diss.pdf">Gaze Tracking for Commodity Portable Devices</a> <br/>
                <b>Erroll Wood</b>, Andreas Bulling, Peter Robinson <br/>
                <i>University of Cambridge, CST Part III (MEng dissertation)</i> <br/>
                <a href="/assets/eww23_part3_diss.pdf">dissertation</a>
                <a href="https://www.youtube.com/watch?v=lPcjQdSzKX4">video</a>
            </p>
        </aside>
    </section>

    <section>
        <h2>2012</h2>
        <img class='sixth' src="part_2_diss.jpg">
        <aside class='five-sixths'>
            <p>
                <a href="/assets/eww23_part2_diss.pdf"> 3D Fractal Exploration using a Scale-Adaptive Sparse Voxel Octree</a> <br/>
                <b>Erroll Wood</b>, Alex Benton, Peter Robinson <br/>
                <i>University of Cambridge, CST Part II (BA dissertation)</i> <br/>
                <a href="/assets/eww23_part2_diss.pdf">dissertation</a>
                <a href="https://code.google.com/p/3d-fractal-explorer/">code</a>
                <a href="https://www.youtube.com/watch?v=oFAiiiJTo50">video</a>
            </p>
        </aside>
    </section>
</body>
</html>